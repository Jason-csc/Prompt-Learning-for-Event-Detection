{"cells":[{"cell_type":"markdown","metadata":{"id":"Fhubqml0-0q4"},"source":["# CS546 Assignment 2: Prompt Learning for Event Detection"]},{"cell_type":"markdown","metadata":{"id":"ak4z2scW-xTl"},"source":["### Google Colab Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1665190105443,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"jD-8mSA9InrY"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24888,"status":"ok","timestamp":1665190138829,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"DNx1Nq2TIo-n","outputId":"6488d4b4-d724-4b70-f7a7-f0d539f8a1f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1665190139132,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"I5sMxXMZIq8r","outputId":"d339303c-5e69-46ec-842d-43ce99a85f72"},"outputs":[{"name":"stdout","output_type":"stream","text":["['helper.py', 'data', '__pycache__', 'checkpoint_best.pt', 'Assignment2.ipynb']\n"]}],"source":["import os\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CS546_A2'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665190139133,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"FUXNv0ZtIsR-"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Central\"\n","time.tzset()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14398,"status":"ok","timestamp":1665190153528,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"ap6uf2UoFmbv","outputId":"3a3cba8a-88d8-4638-a1a0-e994937e3ca2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openprompt\n","  Downloading openprompt-1.0.1-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from openprompt) (0.3.5.1)\n","Collecting datasets\n","  Downloading datasets-2.5.2-py3-none-any.whl (432 kB)\n","\u001b[K     |████████████████████████████████| 432 kB 43.8 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 56.8 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.1 MB/s \n","\u001b[?25hCollecting transformers>=4.10.0\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 48.9 MB/s \n","\u001b[?25hCollecting rouge==1.0.0\n","  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from openprompt) (1.7.3)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from openprompt) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.2 in /usr/local/lib/python3.7/dist-packages (from openprompt) (4.64.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from openprompt) (3.7)\n","Collecting yacs\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge==1.0.0->openprompt) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (5.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 56.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4.10.0->openprompt) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->openprompt) (1.3.5)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 43.2 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 63.3 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->openprompt) (2022.8.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->openprompt) (3.8.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (1.3.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (1.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (22.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (2022.9.24)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 57.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.10.0->openprompt) (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->openprompt) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->openprompt) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->openprompt) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->openprompt) (2022.4)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->openprompt) (3.17.3)\n","Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, yacs, transformers, tensorboardX, sentencepiece, rouge, datasets, openprompt\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.5.2 huggingface-hub-0.10.0 multiprocess-0.70.13 openprompt-1.0.1 responses-0.18.0 rouge-1.0.0 sentencepiece-0.1.96 tensorboardX-2.5.1 tokenizers-0.12.1 transformers-4.22.2 urllib3-1.25.11 xxhash-3.0.0 yacs-0.1.8\n"]}],"source":["!pip install openprompt"]},{"cell_type":"markdown","metadata":{"id":"1eojabBP_A-O"},"source":["### Data Processing"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12956,"status":"ok","timestamp":1665190169007,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"PB4BzD9cmHzW"},"outputs":[],"source":["import tqdm\n","import json\n","from helper import get_vocab, process_data, get_plm, get_template, my_collate_fn, get_verbalizer, to_device, convert_labels_to_list, loss_func, evaluation, predict"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3120,"status":"ok","timestamp":1665190175309,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"E2FXZSLuAfg4","outputId":"c1011cbc-e0c7-4bbd-9b4c-da259ea13aeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'None': 0, 'Catastrophe': 1, 'Presence': 2, 'Know': 3, 'Causation': 4, 'Motion': 5, 'Damaging': 6, 'Influence': 7, 'Destroying': 8, 'Placing': 9, 'Protest': 10, 'Death': 11, 'Warning': 12, 'Arriving': 13, 'Perception_active': 14, 'Sending': 15, 'Preventing_or_letting': 16, 'Hostile_encounter': 17, 'Process_start': 18, 'Attack': 19, 'Traveling': 20, 'Change_event_time': 21, 'Receiving': 22, 'Coming_to_be': 23, 'Reporting': 24, 'Bodily_harm': 25, 'Check': 26, 'Suspicion': 27, 'Killing': 28, 'Earnings_and_losses': 29, 'Cause_to_be_included': 30, 'Statement': 31, 'Cause_change_of_position_on_a_scale': 32, 'Conquering': 33, 'Releasing': 34, 'Coming_to_believe': 35, 'Recovering': 36, 'Choosing': 37, 'Using': 38, 'Military_operation': 39, 'Expressing_publicly': 40, 'Control': 41, 'GetReady': 42, 'Supporting': 43, 'Defending': 44, 'Forming_relationships': 45, 'Becoming_a_member': 46, 'Action': 47, 'Building': 48, 'Removing': 49, 'Request': 50, 'Self_motion': 51, 'Surrendering': 52, 'Deciding': 53, 'Education_teaching': 54, 'Creating': 55, 'Emptying': 56, 'Getting': 57, 'Besieging': 58, 'Agree_or_refuse_to_act': 59, 'Participation': 60, 'Process_end': 61, 'Body_movement': 62, 'Expansion': 63, 'Telling': 64, 'Bearing_arms': 65, 'Name_conferral': 66, 'Use_firearm': 67, 'Change': 68, 'Legal_rulings': 69, 'Giving': 70, 'Arranging': 71, 'Committing_crime': 72, 'Social_event': 73, 'Manufacturing': 74, 'Assistance': 75, 'Motion_directional': 76, 'Surrounding': 77, 'Bringing': 78, 'Robbery': 79, 'Competition': 80, 'Quarreling': 81, 'Communication': 82, 'Containing': 83, 'Writing': 84, 'Expend_resource': 85, 'Hold': 86, 'Being_in_operation': 87, 'Recording': 88, 'Carry_goods': 89, 'Rescuing': 90, 'Judgment_communication': 91, 'Change_tool': 92, 'Cost': 93, 'Departing': 94, 'GiveUp': 95, 'Change_of_leadership': 96, 'Aiming': 97, 'Escaping': 98, 'Hindering': 99, 'Preserving': 100, 'Create_artwork': 101, 'Scrutiny': 102, 'Connect': 103, 'Response': 104, 'Hiding_objects': 105, 'Openness': 106, 'Lighting': 107, 'Confronting_problem': 108, 'Reveal_secret': 109, 'Renting': 110, 'Criminal_investigation': 111, 'Patrolling': 112, 'Arrest': 113, 'Breathing': 114, 'Dispersal': 115, 'Commerce_sell': 116, 'Change_sentiment': 117, 'Collaboration': 118, 'Cure': 119, 'Temporary_stay': 120, 'Commitment': 121, 'Extradition': 122, 'Commerce_pay': 123, 'Convincing': 124, 'Becoming': 125, 'Filling': 126, 'Achieve': 127, 'Cause_change_of_strength': 128, 'Practice': 129, 'Supply': 130, 'Violence': 131, 'Reforming_a_system': 132, 'Scouring': 133, 'Cause_to_amalgamate': 134, 'Come_together': 135, 'Wearing': 136, 'Cause_to_make_progress': 137, 'Legality': 138, 'Employment': 139, 'Rite': 140, 'Adducing': 141, 'Publishing': 142, 'Exchange': 143, 'Ratification': 144, 'Commerce_buy': 145, 'Sign_agreement': 146, 'Imposing_obligation': 147, 'Rewards_and_punishments': 148, 'Institutionalization': 149, 'Testing': 150, 'Ingestion': 151, 'Labeling': 152, 'Kidnapping': 153, 'Submitting_documents': 154, 'Prison': 155, 'Justifying': 156, 'Emergency': 157, 'Vocalizations': 158, 'Terrorism': 159, 'Risk': 160, 'Resolve_problem': 161, 'Revenge': 162, 'Limiting': 163, 'Research': 164, 'Having_or_lacking_access': 165, 'Theft': 166, 'Incident': 167, 'Award': 168}\n"]}],"source":["from openprompt import PromptForClassification\n","from openprompt.prompts import ManualTemplate, SoftTemplate\n","from openprompt import PromptDataLoader\n","from openprompt.prompts import ManualVerbalizer, SoftVerbalizer\n","import torch\n","from transformers import  AdamW, get_linear_schedule_with_warmup\n","\n","train_file = \"train.json\"\n","valid_file =  \"valid.json\"\n","test_file =  \"test.json\"\n","\n","model_file = \"checkpoint_best.pt\"\n","\n","\"\"\" For dataset with full event types \"\"\"\n","# train_file = \"train_full.json\"\n","# valid_file =  \"valid_full.json\"\n","# test_file =  \"test_full.json\"\n","\n","train_dir = os.path.join(GOOGLE_DRIVE_PATH,\"data\",train_file)\n","valid_dir = os.path.join(GOOGLE_DRIVE_PATH,\"data\",valid_file)\n","test_dir = os.path.join(GOOGLE_DRIVE_PATH,\"data\",test_file)\n","model_save_dir = os.path.join(GOOGLE_DRIVE_PATH, model_file)\n","\n","vocabulary = get_vocab(train_dir, valid_dir)\n","dataset = {\n","    \"train\": process_data(train_dir, vocabulary),\n","    \"validation\": process_data(valid_dir, vocabulary),\n","    \"test\": process_data(test_dir, vocabulary)\n","}\n","print(vocabulary)\n","inv_vocabulary = {v:k for k,v in vocabulary.items()}\n","# print(inv_vocabulary)\n"]},{"cell_type":"markdown","metadata":{"id":"nMubJOnNZoDf"},"source":["### Parameters"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":172,"status":"ok","timestamp":1665190222325,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"joFPrlrJZpw-"},"outputs":[],"source":["# info = []\n","# BATCH_SIZE = [5,10,20]\n","# LEARNING_RATE = [5e-5, 1e-4, 2e-4, 1e-3]\n","# WEIGHT_DECAY = [0.01,0.005,0.02]\n","# PLM_MODEL = [(\"albert\",\"albert-base-v2\"),(\"roberta\",\"roberta-base\"),(\"t5\",\"t5-base\"),(\"t5\", \"google/t5-v1_1-base\"),(\"bert\",\"bert-base-cased\")]\n","\n","\n","BATCH_SIZE = 25\n","LEARNING_RATE = 5e-4\n","WEIGHT_DECAY = 0.02\n","PLM_MODEL = (\"t5\",\"t5-base\")\n","SOFT = True # SoftTemplate and SoftVerbalizer if True else Manual\n","\n","use_cuda = True"]},{"cell_type":"markdown","metadata":{"id":"X9CoyfG8Zezt"},"source":["### DataLoader, Verbalizer, Template, Get PLM\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307,"referenced_widgets":["3d01fc0a61b44684b880696971c20fac","109077fe31be40e0aacafe1ebd6526a7","bcab361fbed043f3b45be726fee90633","093d12858708407eaca7674a027ff8d6","677932f458fa4fb2add072dab2070c6c","b364074e6d544faa8354316402aba88b","af8abe6c3d9c4b35b689d6da47a9fe35","a25267796842485bab63ac35cc6382d5","7ecbeb483aae429d9e730bc9430e1ea1","9865f1460dce4240a6a9b18b2629a0cb","06567c655e9d4f86bcbff08902441a87","9802c3bf88f74e12b53ecee9619e13bd","34f66b2f097f4faeb8b41a8b6b5e6568","0e0eabfe271c4b928bb64e711c1026ce","8589d862588241bebbb53e603a50705d","af9d01f8a99d475994de1d5e1cced665","dabec8ba3a2e4f0f922edf965329f16e","c71be95ef434436aa3e207fbf5dbdb62","69fd4aa2774d4d648b99d6dab105bbd5","8a1c273ad95348fe95f4bd1cb82262a1","85d2de61134047fc999dbc4599d7f8f5","b24b2e6c8a7c4508a501b553ffb91568","1403a8ddc2be431a8e474f21ade2bcfa","a4bb70b57e244fd7adcb968c3556b9e9","2c9b7aa9117842d981be29325a2b44fb","bbb21fd606df454e8a2853ca9aa455f5","c6c67a8b887446af9e0e94d817ddf8cf","95b9f920209947fd9965ecd6914c7396","dcccc83a17134aeb8fb926be3ce1fbc9","d5d9e6aa0aa74002a91092d7a98f3451","18077f45025c49f6871d6604979ef5f2","aa9386a8d8944a23945d6168fdfd9f1d","1fa69ec2bc6348f68ccd4434c43d41ff"]},"executionInfo":{"elapsed":93627,"status":"ok","timestamp":1665190317669,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"aDLpco5rZgsT","outputId":"f2d178d1-15be-4fdf-b0a4-a155312e31fc"},"outputs":[],"source":["plm, tokenizer, model_config, WrapperClass = get_plm(PLM_MODEL)\n","template_text = get_template()\n","\n","mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, text=template_text) if SOFT else ManualTemplate(tokenizer=tokenizer, text=template_text)\n","\n","train_dataloader = PromptDataLoader(\n","    dataset=dataset[\"train\"], \n","    template=mytemplate, \n","    tokenizer=tokenizer,\n","    tokenizer_wrapper_class=WrapperClass, \n","    max_seq_length=256, \n","    decoder_max_length=3,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True, \n","    teacher_forcing=False, \n","    predict_eos_token=False,\n","    truncate_method=\"head\"\n",")\n","train_dataloader.dataloader.collate_fn = my_collate_fn\n","\n","validation_dataloader = PromptDataLoader(\n","    dataset=dataset[\"validation\"], \n","    template=mytemplate, \n","    tokenizer=tokenizer,\n","    tokenizer_wrapper_class=WrapperClass, \n","    max_seq_length=256, \n","    decoder_max_length=3,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False, \n","    teacher_forcing=False, \n","    predict_eos_token=False,\n","    truncate_method=\"head\"\n",")\n","validation_dataloader.dataloader.collate_fn = my_collate_fn\n","\n","\n","test_dataloader = PromptDataLoader(\n","    dataset=dataset[\"test\"], \n","    template=mytemplate, \n","    tokenizer=tokenizer,\n","    tokenizer_wrapper_class=WrapperClass, \n","    max_seq_length=256, \n","    decoder_max_length=3,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False, \n","    teacher_forcing=False, \n","    predict_eos_token=False,\n","    truncate_method=\"head\"\n",")\n","test_dataloader.dataloader.collate_fn = my_collate_fn\n","\n","\n","label_words = get_verbalizer(vocabulary)\n","\n","\n","myverbalizer = SoftVerbalizer(tokenizer, plm, vocabulary) if SOFT else ManualVerbalizer(tokenizer, num_classes=len(vocabulary), label_words=label_words,post_log_softmax=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WjQnZJ2C_C2s"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ni6cg3HDNA4P","outputId":"fa598f61-7670-4519-baa9-b08d2545aa59"},"outputs":[],"source":["Prompt_Model = PromptForClassification(plm=plm, template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n","if use_cuda:\n","    Prompt_Model = Prompt_Model.cuda()\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","# it's always good practice to set no decay to biase and LayerNorm parameters\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in Prompt_Model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WEIGHT_DECAY},\n","    {'params': [p for n, p in Prompt_Model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","]\n","\n","\n","EPOCH = 5\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","max_f1 = 0.0\n","max_patience, current_patience, patience_break = 7, 0, False\n","train_f1_history = []\n","valid_f1_history = []\n","train_loss_history = []\n","valid_loss_history = []\n","label_loss_history = []\n","\n","for epoch in range(EPOCH):\n","    tot_loss = 0.0\n","    progress = tqdm.tqdm(total=len(train_dataloader), ncols=150, position=0, leave=True,desc=\"Epoch: \"+str(epoch))\n","    for step, inputs in enumerate(train_dataloader):\n","        if use_cuda:\n","            inputs = to_device(inputs, device)\n","        logits = Prompt_Model(inputs)\n","        labels = inputs['label']\n","        label_list = convert_labels_to_list(labels)\n","        loss = loss_func(logits, label_list)\n","        loss.backward()\n","        tot_loss += loss.item()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if step %100 ==99:\n","            print(\"\\nStep {}, average loss: {}\".format(step, tot_loss/(step+1)), flush=True)\n","            train_loss_history.append(tot_loss/(step+1))\n","            train_pred_labels = predict(logits)\n","            _, _, train_f1, _ = evaluation(label_list, train_pred_labels, vocabulary)\n","            train_f1_history.append(train_f1)\n","            allpreds, alllabels = [], []\n","            \"\"\"Validation\"\"\"\n","            Prompt_Model.eval()\n","            valid_tot_loss = 0.0\n","            with torch.no_grad():\n","                for step, inputs in enumerate(validation_dataloader):\n","                    if use_cuda:\n","                        inputs = to_device(inputs, device)\n","                    logits = Prompt_Model(inputs)\n","                    labels = inputs['label']\n","                    label_list = convert_labels_to_list(labels)\n","                    valid_loss = loss_func(logits, label_list)\n","                    valid_tot_loss += valid_loss.item()\n","                    pred_labels = predict(logits)\n","                    alllabels.extend(label_list)\n","                    allpreds.extend(pred_labels)\n","            Prompt_Model.train()\n","\n","            valid_loss_history.append(valid_tot_loss/len(validation_dataloader))\n","            label_loss_history.append((epoch,step))\n","\n","            p, r, f, total = evaluation(alllabels, allpreds, vocabulary)\n","            print(\"F1-Score: \" + str(f))\n","            valid_f1_history.append(f)\n","            with open(\"results.json\", 'w', encoding='utf-8') as f_out:\n","                f_out.write(json.dumps(total, indent=4))\n","            if f > max_f1:\n","                max_f1 = f\n","                torch.save(Prompt_Model.state_dict(), model_save_dir)\n","                current_patience = 0\n","            else:\n","                current_patience += 1\n","                if current_patience > max_patience:\n","                    patience_break = True\n","                    break\n","        progress.update(1)\n","    progress.close()\n","    if patience_break:\n","        break\n","\n","print(\"F1 score\", max_f1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgptzolGEPpr"},"outputs":[],"source":["# 0.7115806258720351  lr=2*1e-4 batch size = 20 weight_decay = 0.01 t5-base   This text describes a {\"mask\"} event\n","# 0.7244003467874001  lr=1e-4 batch size = 10 weight_decay = 0.01 t5-large   The previous text describes a {\"mask\"} event.\n","# 0.7244364120612574  lr=1e-4 batch size = 10  weight_decay = 0.05 t5-large max_length = 512  The previous text describes the {\"mask\"} event.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jaDc2w1iZ5Q2"},"source":["#### Loss & F1-score Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD__nEhVUWuV"},"outputs":[],"source":["assert len(train_loss_history) == len(valid_loss_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_sZi8WsUqYw"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","xi = list(range(len(train_loss_history)))\n","plt.plot(xi,train_loss_history,  label=\"train_loss\")\n","plt.plot(xi,valid_loss_history,  label=\"valid_loss\")\n","plt.xticks(xi,label_loss_history)\n","plt.ylabel('loss')\n","plt.legend()\n","plt.savefig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-p5RSPbtNIk"},"outputs":[],"source":["xi = list(range(len(train_f1_history)))\n","plt.plot(xi,train_f1_history,  label=\"train_f1\")\n","plt.plot(xi,valid_f1_history,  label=\"valid_f1\")\n","plt.xticks(xi,label_loss_history)\n","plt.ylabel('f1')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ft8cwDMxZ96X"},"source":["### Dump Results for Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLUecXUANg7A"},"outputs":[],"source":["### Dumped out the results for test dataset.\n","\n","    ### You need to write your code here to dump out the dataset using \"test_dataloader\".\n","    ### you need to write out all your model predictions into a file \"output.json\".\n","    ### Each line of the \"output.json\" is the model prediction for the sentence.\n","\n","    ### You may find \"inv_vocabulary\" useful here.\n","\n","    ### Each line should be in the following format:\n","    ###    {\"predictions\": [\"Catastrophe\", \"Conquering\"]}\n","    ###    {\"predictions\": [\"Social_event\"]}\n","    ###    {\"predictions\": []}\n","\n","    ### Note that the sentence order for your output file should be the same with the original file!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gJHE3MeFt1T"},"outputs":[],"source":["test_output_dir = os.path.join(GOOGLE_DRIVE_PATH,\"output.json\")\n","\n","use_cuda = True\n","Prompt_Model = PromptForClassification(plm=plm, template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n","if use_cuda:\n","    Prompt_Model.load_state_dict(torch.load(model_save_dir))\n","else:\n","    Prompt_Model.load_state_dict(torch.load(model_save_dir,map_location=torch.device('cpu')))\n","Prompt_Model.eval()\n","Prompt_Model.cuda()\n","result = []\n","all_pred_test = []\n","with torch.no_grad():\n","    for test_input in test_dataloader:\n","        if use_cuda:\n","            test_input = to_device(test_input, \"cuda\")\n","        logits = Prompt_Model(test_input)\n","        pred_labels = predict(logits)\n","        all_pred_test.extend(pred_labels)\n","        for pred in pred_labels:\n","            res = {\"predictions\":[]}\n","            for p in pred:\n","                res[\"predictions\"].append(inv_vocabulary[p])\n","            result.append(res)\n","\n","\n","with open(test_output_dir, \"w\") as f:\n","    for res in result:\n","        json.dump(res,f)\n","        f.write('\\n')"]},{"cell_type":"markdown","metadata":{"id":"-Inu9-SW0mQE"},"source":["#### Check on Validataion Set"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146707,"status":"ok","timestamp":1665190022423,"user":{"displayName":"Yingzhuo Yu","userId":"03136091848333162966"},"user_tz":300},"id":"6loOY6J32PA9","outputId":"c776647b-2b37-4ee6-c16c-9ddcb26a1a46"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6804308797127468 0.7631896898912606 0.7194381169324222\n","{'Catastrophe': {'prec': 0.6222222222222222, 'rec': 0.7647951441578149, 'f1': 0.6861810755616066}, 'Causation': {'prec': 0.7677419354838709, 'rec': 0.7689822294022617, 'f1': 0.7683615819209039}, 'Motion': {'prec': 0.6056782334384858, 'rec': 0.46601941747572817, 'f1': 0.5267489711934157}, 'Hostile_encounter': {'prec': 0.6307692307692307, 'rec': 0.721830985915493, 'f1': 0.6732348111658456}, 'Process_start': {'prec': 0.8866666666666667, 'rec': 0.8636363636363636, 'f1': 0.875}, 'Attack': {'prec': 0.695859872611465, 'rec': 0.7959927140255009, 'f1': 0.7425658453695836}, 'Killing': {'prec': 0.8134328358208955, 'rec': 0.8983516483516484, 'f1': 0.8537859007832899}, 'Conquering': {'prec': 0.6445623342175066, 'rec': 0.8073089700996677, 'f1': 0.7168141592920354}, 'Social_event': {'prec': 0.5152173913043478, 'rec': 0.6440217391304348, 'f1': 0.5724637681159421}, 'Competition': {'prec': 0.6118980169971672, 'rec': 0.8470588235294118, 'f1': 0.7105263157894737}}\n"]}],"source":["allpreds, alllabels = [], []\n","Prompt_Model = PromptForClassification(plm=plm, template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n","Prompt_Model.load_state_dict(torch.load(model_save_dir))\n","Prompt_Model.eval()\n","Prompt_Model.cuda()\n","with torch.no_grad():\n","    for step, inputs in enumerate(validation_dataloader):\n","        if use_cuda:\n","            inputs = to_device(inputs, \"cuda\")\n","        logits = Prompt_Model(inputs)\n","        labels = inputs['label']\n","        label_list = convert_labels_to_list(labels)\n","        pred_labels = predict(logits)\n","        alllabels.extend(label_list)\n","        allpreds.extend(pred_labels)\n","\n","\n","p, r, f, total = evaluation(alllabels, allpreds, vocabulary)\n","print(p,r,f)\n","print(total)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1665032673376,"user":{"displayName":"Yingzhuo Yu","userId":"18405048797381454339"},"user_tz":300},"id":"VNWqNM3tF0S3","outputId":"28de4e28-0054-4fb1-c0ca-6569489ce0da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Catastrophe & 0.6367 & 0.7527 & 0.6898 \\\n","Causation & 0.8097 & 0.6737 & 0.7354 \\\n","Motion & 0.7115 & 0.3592 & 0.4774 \\\n","Hostile_encounter & 0.6602 & 0.6021 & 0.6298 \\\n","Process_start & 0.8585 & 0.8766 & 0.8675 \\\n","Attack & 0.6955 & 0.8197 & 0.7525 \\\n","Killing & 0.8228 & 0.8929 & 0.8564 \\\n","Conquering & 0.6618 & 0.7608 & 0.7079 \\\n","Social_event & 0.5993 & 0.4674 & 0.5252 \\\n","Competition & 0.6451 & 0.7804 & 0.7063 \\\n"]}],"source":["for k, v in total.items():\n","  print(f\"{k} & {round(v['prec'],4)} & {round(v['rec'],4)} & {round(v['f1'],4)} \\\\\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XkPRnkkejWL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"06567c655e9d4f86bcbff08902441a87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"093d12858708407eaca7674a027ff8d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9865f1460dce4240a6a9b18b2629a0cb","placeholder":"​","style":"IPY_MODEL_06567c655e9d4f86bcbff08902441a87","value":" 1.20k/1.20k [00:00&lt;00:00, 35.9kB/s]"}},"0e0eabfe271c4b928bb64e711c1026ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69fd4aa2774d4d648b99d6dab105bbd5","max":891691430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a1c273ad95348fe95f4bd1cb82262a1","value":891691430}},"109077fe31be40e0aacafe1ebd6526a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b364074e6d544faa8354316402aba88b","placeholder":"​","style":"IPY_MODEL_af8abe6c3d9c4b35b689d6da47a9fe35","value":"Downloading: 100%"}},"1403a8ddc2be431a8e474f21ade2bcfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4bb70b57e244fd7adcb968c3556b9e9","IPY_MODEL_2c9b7aa9117842d981be29325a2b44fb","IPY_MODEL_bbb21fd606df454e8a2853ca9aa455f5"],"layout":"IPY_MODEL_c6c67a8b887446af9e0e94d817ddf8cf"}},"18077f45025c49f6871d6604979ef5f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fa69ec2bc6348f68ccd4434c43d41ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c9b7aa9117842d981be29325a2b44fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d9e6aa0aa74002a91092d7a98f3451","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18077f45025c49f6871d6604979ef5f2","value":791656}},"34f66b2f097f4faeb8b41a8b6b5e6568":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dabec8ba3a2e4f0f922edf965329f16e","placeholder":"​","style":"IPY_MODEL_c71be95ef434436aa3e207fbf5dbdb62","value":"Downloading: 100%"}},"3d01fc0a61b44684b880696971c20fac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_109077fe31be40e0aacafe1ebd6526a7","IPY_MODEL_bcab361fbed043f3b45be726fee90633","IPY_MODEL_093d12858708407eaca7674a027ff8d6"],"layout":"IPY_MODEL_677932f458fa4fb2add072dab2070c6c"}},"677932f458fa4fb2add072dab2070c6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69fd4aa2774d4d648b99d6dab105bbd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ecbeb483aae429d9e730bc9430e1ea1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8589d862588241bebbb53e603a50705d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d2de61134047fc999dbc4599d7f8f5","placeholder":"​","style":"IPY_MODEL_b24b2e6c8a7c4508a501b553ffb91568","value":" 892M/892M [00:18&lt;00:00, 56.1MB/s]"}},"85d2de61134047fc999dbc4599d7f8f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1c273ad95348fe95f4bd1cb82262a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95b9f920209947fd9965ecd6914c7396":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9802c3bf88f74e12b53ecee9619e13bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34f66b2f097f4faeb8b41a8b6b5e6568","IPY_MODEL_0e0eabfe271c4b928bb64e711c1026ce","IPY_MODEL_8589d862588241bebbb53e603a50705d"],"layout":"IPY_MODEL_af9d01f8a99d475994de1d5e1cced665"}},"9865f1460dce4240a6a9b18b2629a0cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a25267796842485bab63ac35cc6382d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4bb70b57e244fd7adcb968c3556b9e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b9f920209947fd9965ecd6914c7396","placeholder":"​","style":"IPY_MODEL_dcccc83a17134aeb8fb926be3ce1fbc9","value":"Downloading: 100%"}},"aa9386a8d8944a23945d6168fdfd9f1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af8abe6c3d9c4b35b689d6da47a9fe35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af9d01f8a99d475994de1d5e1cced665":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24b2e6c8a7c4508a501b553ffb91568":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b364074e6d544faa8354316402aba88b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbb21fd606df454e8a2853ca9aa455f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9386a8d8944a23945d6168fdfd9f1d","placeholder":"​","style":"IPY_MODEL_1fa69ec2bc6348f68ccd4434c43d41ff","value":" 792k/792k [00:00&lt;00:00, 826kB/s]"}},"bcab361fbed043f3b45be726fee90633":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a25267796842485bab63ac35cc6382d5","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ecbeb483aae429d9e730bc9430e1ea1","value":1199}},"c6c67a8b887446af9e0e94d817ddf8cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c71be95ef434436aa3e207fbf5dbdb62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5d9e6aa0aa74002a91092d7a98f3451":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dabec8ba3a2e4f0f922edf965329f16e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcccc83a17134aeb8fb926be3ce1fbc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
